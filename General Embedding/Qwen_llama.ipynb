{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62256a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train = pd.read_csv(\"/teamspace/studios/this_studio/LegalTech-Palak/train.csv\")\n",
    "test = pd.read_csv(\"/teamspace/studios/this_studio/LegalTech-Palak/test.csv\")\n",
    "\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f16146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QWen3-Embedding-8B Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-Embedding-8B\")\n",
    "embed_model = AutoModel.from_pretrained(\"Qwen/Qwen3-Embedding-8B\").to(device)\n",
    "embed_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47273791",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_id = \"/teamspace/studios/this_studio/meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token-Based Chunking\n",
    "def tokenize_and_chunk(text, chunk_size=512, overlap=128):\n",
    "    input_ids = llama_tokenizer.encode(text, truncation=False)\n",
    "    chunks = []\n",
    "    for i in range(0, len(input_ids), chunk_size - overlap):\n",
    "        chunk_ids = input_ids[i:i + chunk_size]\n",
    "        chunk_text = llama_tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Chunks\n",
    "chunked_texts = []\n",
    "chunk_metadata = []\n",
    "\n",
    "for doc_id, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    input_text = str(row[\"Input\"]) if pd.notna(row[\"Input\"]) else \"\"\n",
    "    chunks = tokenize_and_chunk(input_text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_texts.append(chunk)\n",
    "        chunk_metadata.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"chunk_index\": i,\n",
    "            \"title\": row.get(\"Title\", f\"Case {doc_id}\"),\n",
    "            \"original_text\": input_text\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Precomputed Embeddings\n",
    "chunk_embeddings = np.load(\"chunk_embeddings.npy\")\n",
    "\n",
    "# Load FAISS Index\n",
    "index = faiss.read_index(\"faiss_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_cls_embedding(text):\n",
    "    inputs = embed_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = embed_model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "# Qwen Embedding (CLS Token per Chunk)\n",
    "def get_chunk_cls_embedding(text):\n",
    "    inputs = embed_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = embed_model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze(0).cpu().numpy()\n",
    "\n",
    "chunk_embeddings = []\n",
    "for chunk in tqdm(chunked_texts, desc=\"Embedding chunks\"):\n",
    "    chunk_embeddings.append(get_chunk_cls_embedding(chunk))\n",
    "\n",
    "chunk_embeddings = np.vstack(chunk_embeddings).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3414ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "# ========== 7. Build FAISS Index ==========\n",
    "embedding_dim = chunk_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(chunk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "faiss.write_index(index, \"faiss_index.index\")\n",
    "index = faiss.read_index(\"faiss_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Chunks\n",
    "def retrieve_chunks(query, top_k=6):\n",
    "    query_vec = get_chunk_cls_embedding(query).reshape(1, -1)\n",
    "    _, indices = index.search(query_vec, top_k)\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        results.append({\n",
    "            \"chunk\": chunked_texts[i],\n",
    "            \"doc_id\": chunk_metadata[i][\"doc_id\"],\n",
    "            \"title\": chunk_metadata[i][\"title\"],\n",
    "            \"chunk_index\": chunk_metadata[i][\"chunk_index\"],\n",
    "            \"original_text\": chunk_metadata[i][\"original_text\"]\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0267443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_chunks_to_fit_prompt(query_text, retrieved_chunks, max_tokens=4000, reserved_tokens=512):\n",
    "    static_prompt = \"You are a legal assistant AI trained to analyze legal documents.\\n\\nContext:\\n\"\n",
    "    token_budget = max_tokens - len(llama_tokenizer.encode(static_prompt + query_text)) - reserved_tokens\n",
    "\n",
    "    selected_chunks = []\n",
    "    total_tokens = 0\n",
    "    excluded_chunks = []\n",
    "\n",
    "    for c in retrieved_chunks:\n",
    "        tokens = llama_tokenizer.encode(c[\"chunk\"])\n",
    "        if total_tokens + len(tokens) > token_budget:\n",
    "            excluded_chunks.append(c)\n",
    "            continue\n",
    "        selected_chunks.append(c)\n",
    "        total_tokens += len(tokens)\n",
    "\n",
    "    return selected_chunks, excluded_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4375ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RAG Prompt\n",
    "def create_rag_prompt(query_text, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join([f\"Chunk {i+1} (from {c['title']}):\\n{c['chunk']}\" for i, c in enumerate(retrieved_chunks)])\n",
    "    return (\n",
    "        f\"You are a legal assistant AI trained to analyze legal documents.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"New Case:\\n{query_text}\\n\\n\"\n",
    "        f\"Task:\\n\"\n",
    "        f\"1. Predict whether the appeal will be accepted (1) or rejected (0).\\n\"\n",
    "        f\"2. Identify the most relevant sentence(s) from the chunks.\\n\"\n",
    "        f\"3. Explain your reasoning briefly (max 2 lines).\\n\\n\"\n",
    "        f\"Output format:\\n\"\n",
    "        f\"Label: <0 or 1>\\n\"\n",
    "        f\"Explanation: <brief explanation>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13814e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "OUTPUT_CSV_PATH = \"Qwen_prompts_rag_LLM.csv\"\n",
    "\n",
    "# Prepare a list of inputs (queries) and metadata from df\n",
    "records = []\n",
    "\n",
    "print(\"Generating prompts from truncated chunks...\")\n",
    "\n",
    "for doc_id, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    query_text = str(row[\"Input\"]) if pd.notna(row[\"Input\"]) else \"\"\n",
    "    if not query_text.strip():\n",
    "        continue\n",
    "\n",
    "    # Retrieve top-k chunks\n",
    "    retrieved = retrieve_chunks(query_text, top_k=6)\n",
    "\n",
    "    # Truncate to fit token budget\n",
    "    selected_chunks, excluded_chunks = truncate_chunks_to_fit_prompt(query_text, retrieved)\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = create_rag_prompt(query_text, selected_chunks)\n",
    "\n",
    "    # Create record\n",
    "    records.append({\n",
    "        \"doc_id\": doc_id,\n",
    "        \"title\": row.get(\"Title\", f\"Case {doc_id}\"),\n",
    "        \"query\": query_text,\n",
    "        \"num_retrieved_chunks\": len(retrieved),\n",
    "        \"num_selected_chunks\": len(selected_chunks),\n",
    "        \"excluded_chunks\": \"; \".join([c[\"chunk\"][:100] for c in excluded_chunks]),  # optional preview\n",
    "        \"prompt\": prompt,\n",
    "        \"label\": row.get(\"Label\", \"\")\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "df_prompts = pd.DataFrame(records)\n",
    "df_prompts.to_csv(OUTPUT_CSV_PATH, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "print(f\"Saved {len(df_prompts)} prompts to {OUTPUT_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_prompts = pd.read_csv('/Users/gunjananand/Desktop/Lightning AI-Palak/prompts_rag_LLM.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
